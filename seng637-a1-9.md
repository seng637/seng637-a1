> **SENG 637 - Software Testing, Reliability, and Quality**

**Lab. Report \#1 – Introduction to Testing and Defect Tracking**

| Group: 9 |
| -------- |
| Maheen   |
| Dipu     |
| Jasdeep  |
| Dhruvi   |

**Table of Contents**

[1 Introduction](#1-introduction)

[2 High-level description of the exploratory testing plan](#2-high-level-description-of-the-exploratory-testing-plan)

[3 Comparative Evaluation of Exploratory and Manual Functional Testing](#3-comparative-evaluation-of-exploratory-and-manual-functional-testing)

[4 Notes and discussion of the peer reviews of defect reports](#4-notes-and-discussion-of-the-peer-reviews-of-defect-reports)

[5 How the pair testing was managed and team work/effort was divided](#5-how-the-pair-testing-was-managed-and-team-work-and-effort-was-divided)

[6 Challenges overcome, and lessons
learned](#6-challenges-overcome-and-lessons-learned)

[7 Comments/feedback on the lab and lab document itself](#7-comments-and-feedback-on-the-lab-and-lab-document-itself)

# 1 Introduction

This report presents a systematic evaluation of a Java-based Automated Teller Machine (ATM) simulation system using established software testing and defect tracking practices. The system under test (SUT) comprises two consecutive software releases (versions 1.0 and 1.1), allowing assessment of functional correctness, fault handling, and post-fix stability.

Testing activities targeted the ATM’s core operational and transactional behaviors, including system startup and shutdown, session control, cash withdrawals, deposits, account transfers, balance inquiries, and error handling under exceptional conditions. A combination of complementary testing approaches was employed. Exploratory testing was conducted to examine system behavior under unscripted interactions and to expose defects related to edge cases, invalid inputs, and state transitions. Manual scripted testing was subsequently applied using a predefined test suite to verify conformance with documented functional requirements. Regression testing on version 1.1 evaluated the resolution of previously reported defects and identified any regressions introduced by system modifications.

All identified defects were recorded, tracked, and updated using Jira, following standard defect reporting and lifecycle management practices. The assignment specification and published system requirements served as the authoritative basis for expected behavior, test coverage, and defect validation.

---

# 2 High-Level Description of the Exploratory Testing Plan

The exploratory testing phase was designed as an initial, discovery-driven evaluation of the ATM simulation system, with the objective of identifying functional defects, unexpected behaviors, and risk-prone areas prior to structured validation. This phase emphasized rapid learning of system behavior, informed defect discovery, and early risk assessment to guide subsequent testing activities.

Exploratory testing was intentionally positioned as a complement to manual scripted testing, allowing the team to probe system behavior beyond predefined requirements and to observe how the system responded under varied and imperfect user interactions.

## Test Approach

Exploratory testing was conducted using a pair-testing model to maximize coverage, defect detection, and shared system understanding within a limited execution window. The team was divided into two pairs, each assigned responsibility for distinct functional areas, enabling parallel exploration and minimizing redundant effort.

Before execution, testers reviewed the high-level functional requirements outlined in Appendix B to establish baseline expectations for correct system behavior. Given the constrained scope and simulated nature of the ATM system, additional guidance was taken from the System Under Test and Familiarization with the ATM System sections of the assignment documentation to ensure alignment with intended operational flows.

Rather than attempting exhaustive validation, this phase deliberately prioritized breadth over depth, focusing on core functionalities and representative corner cases. This trade-off enabled rapid exposure of defects and behavioral inconsistencies while deferring exhaustive requirement verification to the manual scripted testing phase. As exploratory testing is inherently unscripted and adaptive, coverage decisions were continuously refined based on observed system responses and emerging risk areas.

## Pair Assignment and Functional Focus

Two exploratory testing pairs were formed with clearly defined functional ownership:

- **Pair 1 (Maheen & Dipu)** focused on system startup and shutdown behavior, session handling (including card insertion and PIN validation), and deposit-related functionality.

- **Pair 2 (Jasdeep & Dhruvi)** focused on withdrawal operations, inter-account fund transfers, and balance inquiry functionality.

This functional partitioning allowed independent subsystems to be explored concurrently while maintaining accountability for coverage and defect reporting within each functional area.

## Test Strategy

Exploratory testing was guided by a set of complementary strategies intended to expose both nominal and adverse system behavior:

- **Common-Path Testing**  
  Validation of typical user workflows involving valid credentials and successful transactions, establishing a baseline for expected system operation.

- **Boundary Testing**  
  Examination of system behavior at operational limits, including withdrawal constraints, minimum deposit values, and account balance thresholds, where defects are commonly observed.

- **Exception-Path Testing**  
  Deliberate triggering of error conditions such as invalid PIN entries, insufficient account balances, unreadable cards, and transaction cancellations to assess robustness and error handling.

- **State-Transition Testing**  
  Verification of correct behavior across system state changes, including power on/off transitions, session initiation and termination, and transaction flow progression.

These strategies ensured that exploratory testing addressed both functional correctness and system resilience.

## Test Case Generation

Test scenarios were dynamically derived throughout execution based on:

- Functional requirements specified in Appendix B
- Use cases outlined in Appendix C
- Expected behavior informed by standard ATM usage patterns
- Anticipated failure modes and edge-case conditions observed during testing

Scenario generation remained intentionally flexible, allowing testers to adapt in real time as new behaviors, defects, or inconsistencies were identified.

## Documentation Approach

Each testing pair maintained real-time records of executed scenarios, observed system outputs, and identified defects. All defects were documented with precise reproduction steps, clearly articulated expected and actual outcomes, severity classification, and references to the affected system functionality. Coverage notes were also maintained to track explored areas and reduce overlap between pairs.

This documentation-first approach ensured that exploratory findings could be reliably reproduced, reviewed, and retested during later testing phases.

## Outcome of the Exploratory Testing Phase

This exploratory testing plan enabled early identification of defects that may not be explicitly addressed by predefined test cases, particularly those related to edge conditions, error handling, and state transitions. The insights gained during this phase informed subsequent manual scripted testing and regression testing, contributing to more focused and effective validation of the ATM simulation system.

---

# 3 Comparative Evaluation of Exploratory and Manual Functional Testing

Exploratory testing and manual functional (scripted) testing were employed as complementary validation strategies to assess the correctness, robustness, and behavioral consistency of the ATM simulation system. Although both approaches aim to identify defects, they operate under fundamentally different testing paradigms and therefore expose distinct classes of faults. This section presents a comparative evaluation grounded in empirical observations from testing activities conducted on versions 1.0 and 1.1 of the system.

## Methodological Comparison

| Dimension              | Exploratory Testing                                                                  | Manual Functional (Scripted) Testing                                              |
| ---------------------- | ------------------------------------------------------------------------------------ | --------------------------------------------------------------------------------- |
| Primary Intent         | Early-stage defect discovery and behavioral risk identification                      | Formal verification of conformance to documented requirements                     |
| Control Structure      | Tester-driven, adaptive exploration guided by observed system behavior               | Deterministic execution governed by predefined test cases                         |
| Planning Overhead      | Minimal upfront planning; emphasis on real-time reasoning                            | Significant upfront specification of inputs, steps, and expected outputs          |
| Coverage Dynamics      | Broad, non-uniform coverage across features and system states                        | Structured, requirement-aligned coverage of specified scenarios                   |
| Defect Characteristics | State-transition faults, boundary-condition failures, error-handling inconsistencies | Functional deviations, incorrect outputs, and missing requirement implementations |
| Repeatability          | Lower unless supported by disciplined documentation                                  | High, due to standardized execution and clearly defined oracles                   |
| Tester Dependence      | High; effectiveness strongly correlated with tester expertise                        | Moderate; process-driven execution reduces individual variability                 |
| Role in Regression     | Limited applicability                                                                | Central to regression verification                                                |

## Empirical Findings from the ATM System

Within the context of this project, exploratory testing proved particularly effective at exposing defects related to exception handling, cancellation paths, and transitions between operational states. Its adaptive nature enabled testers to pursue anomalous system responses and investigate behaviors not explicitly anticipated in the predefined test suite. As a result, exploratory testing contributed significantly to early defect discovery and risk identification.

Manual functional testing, in contrast, provided a rigorous and repeatable mechanism for validating the system against its specified functional requirements. Execution of the predefined test suite ensured consistent verification of all core ATM operations, including transaction processing, session management, and error handling scenarios explicitly described in the requirements. Furthermore, manual scripted testing formed the foundation of regression testing for version 1.1, enabling systematic verification of previously reported defects and identification of regressions introduced during defect remediation.

From an efficiency standpoint, exploratory testing delivered high early value with relatively low setup cost, while manual functional testing required greater preparation effort but yielded stronger assurance of requirement compliance and behavioral stability.

## Synthesis and Strategic Implications

The results of this evaluation indicate that exploratory and manual functional testing address complementary quality attributes. Exploratory testing excels at uncovering unanticipated behaviors and defect patterns that emerge from complex interactions and state transitions, making it particularly valuable during early testing phases. Manual functional testing, by contrast, is indispensable for requirement validation, defect verification, and regression testing, where repeatability and traceability are critical.

When applied together, these approaches provided broader defect coverage and deeper insight into system behavior than either method could achieve in isolation. Their combined use enabled both rapid defect discovery and systematic validation, strengthening confidence in the correctness and reliability of the ATM simulation system.

---

# 4 Notes and Discussion of the Peer Reviews of Defect Reports

After completion of the exploratory and manual scripted testing phases, a structured peer review of all defect reports was conducted to improve report quality, consistency, and reproducibility. The peer review process was intentionally performed before regression testing to ensure that all defects entering the verification phase met a uniform standard of documentation and severity classification.

Each testing pair independently reviewed the defect reports authored by the other pair using the defect tracking system. The review focused on evaluating report quality rather than rediscovering defects. Specifically, reviewers assessed the completeness and clarity of reproduction steps, the correctness and precision of expected versus actual outcomes, the appropriateness of severity and priority assignments, accurate version tagging (v1.0 vs. v1.1), and adherence to the reporting guidelines defined in the assignment.

The peer review process identified several recurring issues typical of early-stage defect reporting. Some reports required refinement of reproduction steps to remove ambiguity and ensure consistent reproducibility. In a small number of cases, severity classifications were revised to better reflect the functional impact of the defect rather than its frequency of occurrence. Additionally, overlapping defect reports were identified where similar issues had been independently discovered by both pairs during exploratory testing.

Based on peer feedback, corrective actions were applied to the defect repository. Duplicate and overlapping defects were consolidated into single canonical reports, reproduction steps were expanded and clarified where necessary, and severity levels were adjusted to improve consistency across the defect set. These revisions resulted in clearer, more actionable defect reports that could be reliably retested during regression testing.

Overall, the peer review process significantly improved the quality and maintainability of the defect repository. It ensured consistency in defect classification, enhanced reproducibility, and established a shared understanding of defect impact across the team. This review phase contributed directly to more efficient regression testing and reinforced the importance of disciplined defect reporting as a critical component of the software testing lifecycle.

---

# 5 How the Pair Testing Was Managed and Team Work and Effort Was Divided

Pair testing was adopted as the primary collaboration model throughout all testing phases to enhance defect detection, reduce individual oversight, and promote shared understanding of system behavior. Responsibilities were deliberately structured to balance execution efficiency with analytical rigor and reporting quality.

## Pair Testing Structure and Role Allocation

During the exploratory testing phase, the team was divided into two pairs, each operating at a single workstation. Within each pair, roles were explicitly defined and enforced:

- **Driver (Test Executor):** Responsible for interacting directly with the system under test, executing test scenarios, and navigating transaction workflows.
- **Observer (Reviewer/Recorder):** Responsible for monitoring system behavior, identifying deviations from expected outcomes, validating results, and documenting defects in the defect tracking system.

Roles were periodically rotated within each pair to ensure balanced participation, mitigate role fatigue, and allow all team members to gain experience in both execution and analytical review. This rotation also helped surface defects that may have been overlooked under a single-role perspective.

## Coordination and Communication

Coordination between pairs was maintained through brief synchronization discussions conducted before and after testing sessions. These discussions were used to clarify functional coverage boundaries, share observations of anomalous behavior, and minimize redundant exploration of the same system components. When ambiguities arose regarding expected system behavior, the team collectively referred to the assignment specification and system requirements to establish a consistent and defensible interpretation.

This structured communication ensured alignment across pairs while preserving independent exploration during testing execution.

## Manual Scripted and Regression Testing Collaboration

During the manual scripted testing phase, the team transitioned from pair-based execution to a fully collaborative testing model. Responsibilities for test execution, defect documentation, and test progression coordination were dynamically assigned and rotated among team members. This approach ensured consistent execution of the predefined test suite, adherence to reporting standards, and shared accountability for coverage.

For regression testing, previously reported defects were distributed among team members for individual verification against version 1.1 of the system. Each member was responsible for retesting assigned defects, updating defect status, and documenting outcomes in the tracking system. Any newly discovered defects were reviewed collectively before being reported to ensure they had not been previously identified and to maintain consistency in classification.

## Assessment of the Pair Testing Approach

The pair testing methodology proved effective in improving both test coverage and defect report quality. Real-time review during execution reduced the likelihood of missed defects, while collaborative decision-making improved consistency in defect severity classification and documentation. The structured division of effort, role rotation, and continuous communication contributed to efficient testing execution and increased confidence in the completeness and reliability of the testing results.

---

# 6 Challenges Overcome and Lessons Learned

The testing effort revealed a set of technical and process-related challenges that required deliberate resolution to maintain consistency, accuracy, and efficiency across testing phases. Rather than treating these issues as isolated obstacles, they were addressed through structured mitigation strategies that improved the rigor of the testing workflow and the quality of the resulting defect artifacts. The challenges encountered and the corresponding lessons learned are summarized below.

## Key Challenges and Mitigation

- **Ambiguity in expected system behavior** for exceptional scenarios (e.g., transaction cancellations, invalid input handling, and state transitions) due to implicit or underspecified requirements.  
  **Mitigation:** A shared interpretation framework was established through repeated reference to the assignment specification and use case documentation, ensuring consistent decision-making across testers.

- **Inconsistent defect severity and priority classification** during early testing stages, particularly for defects affecting usability versus core transactional correctness.  
  **Mitigation:** Structured peer review and calibration discussions were used to align severity definitions and improve consistency across the defect repository.

- **Coverage and time management challenges** inherent to exploratory testing, where unrestricted exploration risked disproportionate focus on isolated behaviors.  
  **Mitigation:** Functional partitioning between testing pairs and continuous awareness of coverage boundaries helped maintain balanced exploration.

- **Risk of fragmented system understanding** when defects were discovered independently by different testers.  
  **Mitigation:** Pair testing, real-time discussion, and post-session synchronization ensured shared understanding and reduced individual bias.

## Lessons Learned

- Exploratory and scripted testing provide complementary value, combining rapid discovery of unanticipated behaviors with systematic requirement verification.
- Disciplined defect documentation is foundational, directly enabling effective regression testing and reliable defect verification.
- Severity classification requires alignment, not intuition alone; shared criteria improve defensibility and prioritization.
- Structured collaboration mechanisms including pair testing, peer review, and role rotation significantly enhance defect detection accuracy and reporting quality.
- Process discipline scales quality, particularly in multi-phase testing workflows involving regression validation.

---

# 7 Comments and Feedback on the Lab and Lab Document Itself

Overall, the lab provided a well-structured and effective framework for applying software testing and defect tracking concepts in a practical setting. The combination of exploratory testing, manual scripted testing, and regression testing closely reflected real-world testing workflows and reinforced the importance of using multiple testing strategies to achieve comprehensive coverage.

The lab documentation was generally clear and logically organized, particularly the detailed system description, use cases, and predefined test suite. These components provided a solid foundation for planning and executing testing activities. The requirement to use an industry-standard defect tracking tool further enhanced the realism and educational value of the assignment.

One area for potential improvement is the clarification of expected behavior for certain exceptional scenarios, such as transaction cancellation flows and edge-case handling. Providing additional guidance or examples for these cases could reduce ambiguity and help ensure more consistent interpretation across testing teams. Minor inconsistencies in test case numbering were also observed, and addressing these would improve usability of the test suite.

Despite these minor issues, the lab was a valuable and meaningful exercise that strengthened understanding of software testing methodologies, defect reporting practices, and collaborative testing workflows. The assignment effectively balanced technical rigor with practical applicability and served as a strong introduction to systematic software quality assurance.
